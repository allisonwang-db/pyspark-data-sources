[tool.poetry]
name = "pyspark-data-sources"
version = "0.1.2"
description = "Custom Spark data sources for reading and writing data in Apache Spark, using the Python Data Source API"
authors = ["allisonwang-db <allison.wang@databricks.com>"]
license = "Apache License 2.0"
readme = "README.md"
packages = [{ include = "pyspark_datasources" }]

[tool.poetry.dependencies]
python = "^3.9"
requests = "^2.28.1"
faker = { version = "^23.1.0", optional = true }
mkdocstrings = { extras = ["python"], version = "^0.24.0" }
datasets = { version = "^2.17.0", optional = true }
validators = "^0.22.0"
httpx = "^0.27.0"
authlib = "^1.3.0"

[tool.poetry.extras]
faker = ["faker"]
datasets = ["datasets"]
all = ["faker", "datasets"]

[tool.poetry.group.dev.dependencies]
pytest = "^8.0.0"
grpcio = "^1.60.1"
grpcio-status = "^1.60.1"
pandas = "^2.2.0"
pyarrow = "^15.0.0"
mkdocs-material = "^9.5.9"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
