[tool.poetry]
name = "pyspark-data-sources"
version = "0.1.5"
description = "Custom Spark data sources for reading and writing data in Apache Spark, using the Python Data Source API"
authors = ["allisonwang-db <allison.wang@databricks.com>"]
license = "Apache License 2.0"
readme = "README.md"
packages = [
    { include = "pyspark_datasources" },
]

[tool.poetry.dependencies]
python = "^3.9"
requests = "^2.31.0"
faker = {version = "^23.1.0", optional = true}
mkdocstrings = {extras = ["python"], version = "^0.24.0"}
datasets = {version = "^2.17.0", optional = true}
databricks-sdk = {version = "^0.28.0", optional = true}

[tool.poetry.extras]
faker = ["faker"]
datasets = ["datasets"]
databricks = ["databricks-sdk"]
all = ["faker", "datasets", "databricks"]

[tool.poetry.group.dev.dependencies]
pytest = "^8.0.0"
grpcio = "^1.60.1"
grpcio-status = "^1.60.1"
pandas = "^2.2.0"
pyarrow = "^15.0.0"
mkdocs-material = "^9.5.9"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
