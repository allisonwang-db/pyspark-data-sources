[tool.poetry]
name = "pyspark-data-sources"
version = "0.1.9"
description = "Custom Spark data sources for reading and writing data in Apache Spark, using the Python Data Source API"
authors = ["allisonwang-db <allison.wang@databricks.com>"]
license = "Apache License 2.0"
readme = "README.md"
packages = [
    { include = "pyspark_datasources" },
]

[tool.poetry.dependencies]
python = ">=3.9,<3.13"
pyarrow = ">=11.0.0"
requests = "^2.31.0"
faker = "^23.1.0"
mkdocstrings = {extras = ["python"], version = "^0.28.0"}
datasets = {version = "^2.17.0", optional = true}
databricks-sdk = {version = "^0.28.0", optional = true}
kagglehub = {extras = ["pandas-datasets"], version = "^0.3.10", optional = true}
simple-salesforce = {version = "^1.12.0", optional = true}

[tool.poetry.extras]
faker = ["faker"]
datasets = ["datasets"]
databricks = ["databricks-sdk"]
kaggle = ["kagglehub"]
lance = ["pylance"]
salesforce = ["simple-salesforce"]
all = ["faker", "datasets", "databricks-sdk", "kagglehub", "simple-salesforce"]

[tool.poetry.group.dev.dependencies]
pytest = "^8.0.0"
pytest-cov = "^4.0.0"
grpcio = "^1.60.1"
grpcio-status = "^1.60.1"
pandas = "^2.2.0"
mkdocs-material = "^9.5.40"
pyspark = "4.0.0"
ruff = "^0.6.0"

[tool.ruff]
line-length = 100
target-version = "py39"

[tool.ruff.format]
quote-style = "double"
indent-style = "space"

[tool.ruff.lint]
select = ["E", "F", "I", "UP"]
ignore = []

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
