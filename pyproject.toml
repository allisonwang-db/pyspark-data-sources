[tool.poetry]
name = "pyspark-data-sources"
version = "0.1.7"
description = "Custom Spark data sources for reading and writing data in Apache Spark, using the Python Data Source API"
authors = ["allisonwang-db <allison.wang@databricks.com>"]
license = "Apache License 2.0"
readme = "README.md"
packages = [
    { include = "pyspark_datasources" },
]

[tool.poetry.dependencies]
python = ">=3.9"
pyarrow = ">=11.0.0"
requests = "^2.31.0"
faker = "^23.1.0"
mkdocstrings = {extras = ["python"], version = "^0.28.0"}
datasets = {version = "^2.17.0", optional = true}
databricks-sdk = {version = "^0.28.0", optional = true}
kagglehub = {extras = ["pandas-datasets"], version = "^0.3.10", optional = true}
pylance = {version = "^0.31.0", optional = true}

[tool.poetry.extras]
faker = ["faker"]
datasets = ["datasets"]
databricks = ["databricks-sdk"]
kaggle = ["kagglehub"]
lance = ["pylance"]
all = ["faker", "datasets", "databricks-sdk", "kagglehub", "pylance"]

[tool.poetry.group.dev.dependencies]
pytest = "^8.0.0"
grpcio = "^1.60.1"
grpcio-status = "^1.60.1"
pandas = "^2.2.0"
mkdocs-material = "^9.5.40"
pyspark = ">=4.0.0,<4.1.0"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
